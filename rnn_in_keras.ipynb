{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use an RNN to classify IMDB movie reviews by their sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D\n",
    "# the RNN layer \n",
    "from keras.layers import SimpleRNN # new! \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/rnn'\n",
    "\n",
    "# training:\n",
    "# not good use of data per Epochs\n",
    "epochs = 16 # way more!\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 64 \n",
    "# increase the number of words beacuse of the effeciency of RNN\n",
    "n_unique_words = 10000 \n",
    "# simple RNN are not good with remmebring\n",
    "max_review_length = 100 # lowered due to vanishing gradient over time\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# RNN layer architecture:\n",
    "n_rnn = 256 \n",
    "drop_rnn = 0.2\n",
    "# Not using Dense layer, a commun practice: from Embedding to RNN to Output\n",
    "# dense layer architecture: \n",
    "# n_dense = 256\n",
    "# dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # removed n_words_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(SimpleRNN(n_rnn, dropout=drop_rnn))\n",
    "# model.add(Dense(n_dense, activation='relu')) # typically don't see top dense layer in NLP like in \n",
    "# model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               82176     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 722,433\n",
      "Trainable params: 722,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/16\n",
      "25000/25000 [==============================] - 146s - loss: 0.7004 - acc: 0.5150 - val_loss: 0.6912 - val_acc: 0.5224\n",
      "Epoch 2/16\n",
      "25000/25000 [==============================] - 111s - loss: 0.6874 - acc: 0.5389 - val_loss: 0.6816 - val_acc: 0.5486\n",
      "Epoch 3/16\n",
      "25000/25000 [==============================] - 111s - loss: 0.6711 - acc: 0.5770 - val_loss: 0.6768 - val_acc: 0.5508\n",
      "Epoch 4/16\n",
      "25000/25000 [==============================] - 111s - loss: 0.6427 - acc: 0.6227 - val_loss: 0.6555 - val_acc: 0.5928\n",
      "Epoch 5/16\n",
      "25000/25000 [==============================] - 113s - loss: 0.5821 - acc: 0.6871 - val_loss: 0.6576 - val_acc: 0.5874\n",
      "Epoch 6/16\n",
      "25000/25000 [==============================] - 125s - loss: 0.5181 - acc: 0.7518 - val_loss: 0.5891 - val_acc: 0.6941\n",
      "Epoch 7/16\n",
      "25000/25000 [==============================] - 131s - loss: 0.5671 - acc: 0.7184 - val_loss: 0.6060 - val_acc: 0.6681\n",
      "Epoch 8/16\n",
      "25000/25000 [==============================] - 134s - loss: 0.4579 - acc: 0.7972 - val_loss: 0.5197 - val_acc: 0.7482\n",
      "Epoch 9/16\n",
      "25000/25000 [==============================] - 111s - loss: 0.4186 - acc: 0.8222 - val_loss: 0.4946 - val_acc: 0.7772\n",
      "Epoch 10/16\n",
      "25000/25000 [==============================] - 113s - loss: 0.3807 - acc: 0.8445 - val_loss: 0.4999 - val_acc: 0.7898\n",
      "Epoch 11/16\n",
      "25000/25000 [==============================] - 112s - loss: 0.5215 - acc: 0.7371 - val_loss: 0.5651 - val_acc: 0.7193\n",
      "Epoch 12/16\n",
      "25000/25000 [==============================] - 111s - loss: 0.3741 - acc: 0.8480 - val_loss: 0.5173 - val_acc: 0.7770\n",
      "Epoch 13/16\n",
      "25000/25000 [==============================] - 112s - loss: 0.3653 - acc: 0.8499 - val_loss: 0.5418 - val_acc: 0.7662\n",
      "Epoch 14/16\n",
      "25000/25000 [==============================] - 111s - loss: 0.3484 - acc: 0.8609 - val_loss: 0.5671 - val_acc: 0.7746\n",
      "Epoch 15/16\n",
      "25000/25000 [==============================] - 113s - loss: 0.3249 - acc: 0.8733 - val_loss: 0.5644 - val_acc: 0.7816\n",
      "Epoch 16/16\n",
      "25000/25000 [==============================] - 113s - loss: 0.3231 - acc: 0.8739 - val_loss: 0.5678 - val_acc: 0.7802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e566a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80.6% validation accuracy in epoch 4\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.15.hdf5\") # zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24992/25000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15e566d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'84.87'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
